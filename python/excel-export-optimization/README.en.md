# ðŸ“¦ Large Dataset Export Optimizer

Exporting large datasets efficiently from web applications can be challenging â€” especially when dealing with Excel or CSV formats. This repository demonstrates three approaches to exporting over 1 million rows with better performance and user experience.

> ðŸ” Real-world inspired â€” generalized for open sharing.

---

## ðŸš€ Features

- âœ… Export data as Excel using `openpyxl`
- âš¡ Export data as Excel using `xlsxwriter` (fast!)
- âš¡âš¡ Export data as CSV (super fast!)
- ðŸ§© Automatically split into multiple files if data exceeds threshold
- ðŸ“¦ Zip all files into a single downloadable response
- ðŸ“Š Logs time taken per method

---

## ðŸ“‚ Directory Structure
```plaintext
ðŸ“ large-export-optimizer/
â”£ ðŸ“œ openpyxl_export.py
â”£ ðŸ“œ xlsxwriter_export.py
â”£ ðŸ“œ csv_export.py
â”£ ðŸ“œ README.en.md
â”— ðŸ“œ README.ko.md
```

---

## ðŸ“„ Code Overview

### `openpyxl_export.py`
- Standard Excel export using `openpyxl`
- Good for styled spreadsheets, but **slower** for large datasets

### `xlsxwriter_export.py`
- Optimized Excel export using `xlsxwriter`
- **2~3x faster** than `openpyxl` in large data use cases

### `csv_export.py`
- Fastest method using plain `csv`
- Ideal for raw data exports (e.g. analytics, logs)
- Automatically split into chunks if too large

---

## ðŸ§ª Performance Example (1,025,731 rows)

| Method        | Duration   | Format | Notes         |
|---------------|------------|--------|---------------|
| openpyxl      | ~7 min     | .xlsx  | Slowest       |
| xlsxwriter    | ~2 min     | .xlsx  | Recommended   |
| csv           | ~1 min     | .csv   | Fastest       |

> ðŸ’¡ Results based on local Django test with generator-based data

---

## ðŸ”§ Customization

You can adjust:

```python
CHUNK_SIZE = 100_000
```

And replace the dummy_data_generator() with your real queryset or data source.
