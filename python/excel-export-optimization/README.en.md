# ğŸ“¦ Large Dataset Export Optimizer

Exporting large datasets efficiently from web applications can be challenging â€” especially when dealing with Excel or CSV formats. This repository demonstrates three approaches to exporting over 1 million rows with better performance and user experience.

> ğŸ” Real-world inspired â€” generalized for open sharing.

---

## ğŸš€ Features

- âœ… Export data as Excel using `openpyxl`
- âš¡ Export data as Excel using `xlsxwriter` (fast!)
- âš¡âš¡ Export data as CSV (super fast!)
- ğŸ§© Automatically split into multiple files if data exceeds threshold
- ğŸ“¦ Zip all files into a single downloadable response
- ğŸ“Š Logs time taken per method

---

## ğŸ“‚ Directory Structure
ğŸ“ large-export-optimizer/
â”£ ğŸ“œ openpyxl_export.py
â”£ ğŸ“œ xlsxwriter_export.py
â”£ ğŸ“œ csv_export.py
â”£ ğŸ“œ README.en.md
â”— ğŸ“œ README.ko.md

---

## ğŸ“„ Code Overview

### `openpyxl_export.py`
- Standard Excel export using `openpyxl`
- Good for styled spreadsheets, but **slower** for large datasets

### `xlsxwriter_export.py`
- Optimized Excel export using `xlsxwriter`
- **2~3x faster** than `openpyxl` in large data use cases

### `csv_export.py`
- Fastest method using plain `csv`
- Ideal for raw data exports (e.g. analytics, logs)
- Automatically split into chunks if too large

---

## ğŸ§ª Performance Example (1,025,731 rows)

| Method        | Duration   | Format | Notes         |
|---------------|------------|--------|---------------|
| openpyxl      | ~7 min     | .xlsx  | Slowest       |
| xlsxwriter    | ~2 min     | .xlsx  | Recommended   |
| csv           | ~1 min     | .csv   | Fastest       |

> ğŸ’¡ Results based on local Django test with generator-based data

---

## ğŸ”§ Customization

You can adjust:

```python
CHUNK_SIZE = 100_000
```

And replace the dummy_data_generator() with your real queryset or data source.